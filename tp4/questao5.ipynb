{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7c3b401",
   "metadata": {},
   "source": [
    "- Usaremos diversas bibliotecas: nltk, pandas e scikit-learn\n",
    "- Lembre se que algumas bibliotecas devem ser instaladas!\n",
    "- Usei \"pip install *nome da biblioteca*\" pra fazer a instalação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74bb0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914b1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler o arquivo com os dados, mostre uma amostra do arquivo e exibe a \n",
    "# contagem de cada uma das colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e1c737e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('~/Documents/workspace/gsi024/tp4/reforma_previdencia_rotulado.csv',encoding='utf-8', sep=';')\n",
    "# dataset = pd.read_csv(r\"C:\\Users\\Miani\\Dropbox\\Rodrigo\\Trabalho\\UFU\\Disciplinas\\Organização e Recuperação da Informação\\Exercícios\\TP\\TP4\\Tweets_Mg.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b55e7708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pressionem Queremos a reforma da previdência d...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#EPTV1 Parabéns pela imparcialidade. Mostrando...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@dep_paulinho TU É UM CANALHA. INDO CONTRA A R...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Em mais um golpe do Centrão, aquela grande fre...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eles acham que o objetivo é só lula livre e ca...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Classificação\n",
       "0  Pressionem Queremos a reforma da previdência d...      Positivo\n",
       "1  #EPTV1 Parabéns pela imparcialidade. Mostrando...      Positivo\n",
       "2  @dep_paulinho TU É UM CANALHA. INDO CONTRA A R...      Positivo\n",
       "3  Em mais um golpe do Centrão, aquela grande fre...      Positivo\n",
       "4  Eles acham que o objetivo é só lula livre e ca...      Positivo"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d8f2856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet            2232\n",
       "Classificação    2232\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bcc884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos contar quantos tweets de cada tipo existem: neutro, positivo e negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28d0cba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet            780\n",
       "Classificação    780\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.Classificação=='Neutro'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8854caf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet            740\n",
       "Classificação    740\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.Classificação=='Positivo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcbbe830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet            712\n",
       "Classificação    712\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset.Classificação=='Negativo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63384d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisamos criar váriaveis diferentes para armazenar os tweets e a sua classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e483345",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = dataset['Tweet'].values\n",
    "classes = dataset['Classificação'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a617a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos treinar o nosso primeiro modelo de classificação de texto. \n",
    "# Algumas coisas são importantes aqui:\n",
    "\n",
    "# 1) Precisamos definir como representar os tweets (BoW)\n",
    "# 2) Precisamos definir qual algoritmo de classificação será usado \n",
    "\n",
    "\n",
    "### Breve explicação sobre o funcionamento de algoritmos de classificação: ###\n",
    "# O algoritmo irá relacionar o conteúdo da BoW (1,0,2,0,1) com a respectiva classificação 'Neutro'. Usando diferentes critérios e com auxílio dos dados\n",
    "# analisados, o algoritmo irá criar \"regras\" para identificar/generalizar cada uma das classificações - Neutro, Positivo e Negativo. Chamamos esse conjunto de regras de \"modelo\".\n",
    "# Feito isso, quando o modelo receber um novo tweet (BoW) sem a classificação, com base nas regras que foram criadas, ele irá tentar \"adivinhar\" qual será a classe daquele tweet.\n",
    "# ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e47cfc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para resolver o problema 1), vamos usar somente o TF - CountVectorizer. Essa função já limpa aqueles caracteres esquisitos que vimos lá em cima.\n",
    "\n",
    "# Na linha 1, criamos um objeto do tipo CountVectorizer chamado vectorizer. Após isso, na linha 2, usamos o objeto vectorizer para calcular a frequência de todas as palavras da lista de tweets e armazenamos seu retorno em freq_tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48a4a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "freq_tweets = vectorizer.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04a51203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para resolver o problema 2), vamos trabalhar com um algoritmo de classificação chamado de Naive Bayes. Ele é baseado em probabilidades.\n",
    "# Na linha 1, criamos um objeto chamado modelo do tipo Naive Bayes Multinomial.\n",
    "# Na linha 2, treinamos o modelo usando a frequência de palavras (freq_tweets) e as classes de cada instância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ad03d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f234f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos fazer alguns testes \"manuais\". Ou seja, fornecer como entrada para o modelo alguns tweets\n",
    "# e deixar que ele faça a classificação. Na opinião de vocês, qual seria a classificação para cada um desses\n",
    "# tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e9eff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A reforma da previdencia foi muito boa', 'A reforma foi péssima', 'Não gostei da reforma', 'A reforma foi tenebrosa', 'A reforma da previdência é uma das reformas já feitas']\n"
     ]
    }
   ],
   "source": [
    "testes = ['A reforma da previdencia foi muito boa','A reforma foi péssima','Não gostei da reforma','A reforma foi tenebrosa','A reforma da previdência é uma das reformas já feitas']\n",
    "print(testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ef3d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo a BoW dos tweets dentro da variável testes usando o TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91834942",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_testes = vectorizer.transform(testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a96e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faço a classificação dos tweets de testes usando o modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6aa94e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Negativo', 'Positivo', 'Positivo', 'Positivo'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.predict(freq_testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d7a21c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vimos que o modelo funciona! Tem alguns erros mas isso faz parte do processo. \n",
    "# O próximo passo agora é fazer uma avaliação mais robusta do modelo. \n",
    "# Vamos usar uma parte da base de dados para treinar e a outra parte para testar. \n",
    "# Uma maneira de se fazer isso é usando um método chamado de \"Cross Validation\" ou \"Validação cruzada\".\n",
    "# Essta técnica consiste em dividir todo o conjunto de dados em K partes, que serão chamadas de folds. \n",
    "# Dessas partes, uma será separada para teste e as outras restantes serão usadas para treinar o modelo.\n",
    "\n",
    "## Exemplo ##\n",
    "\n",
    "# Para k = 10 , imagine que todo nosso dado de treino foi dividido em 10 partes distintas.\n",
    "# Assim, o modelo será treinado com 9 partes, e testado com a parte restante. Esse processo é repetido até que o modelo seja treinado e testado com todas as partes do dado.\n",
    "\n",
    "# A variável \"resultados\" guarda as previsões feitas pelo pelo modelo usando a validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa087b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd92bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pronto! Modelo treinado e validado! Como descobrir o desempenho do modelo? Inicialmente, usaremos uma\n",
    "# medida chamada de Acurácia que nada mais é do que o percentual de acertos que o modelo teve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9643173b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6097670250896058"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "011a5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E se eu quiser saber o desempenho por cada uma das classes? Talvez o modelo acerte mais uma classe\n",
    "# do que a outra..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0d8e0631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.59      0.58      0.58       712\n",
      "      Neutro       0.68      0.56      0.62       780\n",
      "    Positivo       0.58      0.69      0.63       740\n",
      "\n",
      "    accuracy                           0.61      2232\n",
      "   macro avg       0.61      0.61      0.61      2232\n",
      "weighted avg       0.62      0.61      0.61      2232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(classes,resultados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "622d6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E seu eu quiser saber a quantidade de acertos por classe? Nesse caso precisamos mostrar \n",
    "# a matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "570242f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   Negativo  Neutro  Positivo   All\n",
      "Real                                      \n",
      "Negativo       414     116       182   712\n",
      "Neutro         150     439       191   780\n",
      "Positivo       141      91       508   740\n",
      "All            705     646       881  2232\n"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
